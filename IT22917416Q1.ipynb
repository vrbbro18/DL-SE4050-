{"cells": [{"cell_type": "markdown", "source": ["# Task 1: Understanding Basic RNN Architecture\n", "This notebook implements a simple RNN to predict the next value in a sequence of numbers."], "metadata": {}}, {"cell_type": "code", "source": ["import numpy as np\n", "import tensorflow as tf\n", "from tensorflow.keras.models import Sequential\n", "from tensorflow.keras.layers import SimpleRNN, Dense\n", "\n", "# Generate a simple sequence dataset\ndef generate_sequence(n=100):\n", "    X = np.array([i for i in range(n)])\n", "    y = np.array([i+1 for i in range(n)])\n", "    return X, y\n", "\n", "X, y = generate_sequence(50)\n", "X = X.reshape((X.shape[0], 1, 1))\n", "\n", "# Build RNN model\n", "model = Sequential([\n", "    SimpleRNN(units=10, activation='relu', input_shape=(1,1)),\n", "    Dense(1)\n", "])\n", "model.compile(optimizer='adam', loss='mse')\n", "\n", "history = model.fit(X, y, epochs=50, batch_size=2, verbose=0)\n", "predictions = model.predict(X, verbose=0)\n", "print(predictions[:5])"], "metadata": {}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": ["### Observations\n", "- Increasing the number of hidden units in the `SimpleRNN` layer allowed the model to capture more complex sequence patterns.\n", "- Adjusting the number of epochs improved learning. More epochs generally reduced error, but too many led to overfitting.\n", "- Batch size had a significant impact: small batch size \u2192 better sequence learning but slower; large batch size \u2192 faster but less accurate.\n", "- With proper tuning, predicted values closely aligned with the actual sequence."], "metadata": {}}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}